{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "csv_names = [\"Drop_yolo.csv\", \"Grasp_yolo.csv\", \"ReachPick_yolo.csv\", \"ReachDrop_yolo.csv\"]\n",
    "#csv_names = [\"ReachDrop_yolo.csv\"]\n",
    "\n",
    "# Load and merge CSV files\n",
    "dataframes = [pd.read_csv(name) for name in csv_names]\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Keep only the rows where \"cls\" is \"red cube\"\n",
    "#filtered_df = merged_df[merged_df['cls'] == 'blue cube']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>conf</th>\n",
       "      <th>cls</th>\n",
       "      <th>world_x</th>\n",
       "      <th>world_y</th>\n",
       "      <th>world_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.912683</td>\n",
       "      <td>red cube</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.180255</td>\n",
       "      <td>0.871774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>244.5</td>\n",
       "      <td>93.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.901834</td>\n",
       "      <td>blue cube</td>\n",
       "      <td>0.012437</td>\n",
       "      <td>0.233266</td>\n",
       "      <td>0.946969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.0</td>\n",
       "      <td>136.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.879418</td>\n",
       "      <td>green cube</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>-0.180102</td>\n",
       "      <td>0.824637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.912683</td>\n",
       "      <td>red cube</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.180255</td>\n",
       "      <td>0.871774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>136.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.879418</td>\n",
       "      <td>green cube</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>-0.180102</td>\n",
       "      <td>0.824637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      px     py     w     h      conf         cls   world_x   world_y  \\\n",
       "0   47.0  121.5  30.0  29.0  0.912683    red cube  0.000116 -0.180255   \n",
       "1  244.5   93.5  23.0  31.0  0.901834   blue cube  0.012437  0.233266   \n",
       "2   51.0  136.5  30.0  31.0  0.879418  green cube  0.000068 -0.180102   \n",
       "3   47.0  121.5  30.0  29.0  0.912683    red cube  0.000116 -0.180255   \n",
       "4   51.0  136.5  30.0  31.0  0.879418  green cube  0.000068 -0.180102   \n",
       "\n",
       "    world_z  \n",
       "0  0.871774  \n",
       "1  0.946969  \n",
       "2  0.824637  \n",
       "3  0.871774  \n",
       "4  0.824637  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0007619680808784637, -0.17993275737890543, 0.8657178686889888)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load your dataframe (df)\n",
    "# columns: px, py, w, h, conf, cls, world_x, world_y, world_z\n",
    "\n",
    "df = merged_df\n",
    "\n",
    "# Input features (image space)\n",
    "X = df[[\"px\", \"py\"]].values\n",
    "\n",
    "# Targets (world space)\n",
    "Y = df[[\"world_x\", \"world_y\", \"world_z\"]].values\n",
    "\n",
    "# Fit affine mapping for each world coordinate\n",
    "reg_x = LinearRegression().fit(np.c_[X, np.ones(len(X))], Y[:,0])\n",
    "reg_y = LinearRegression().fit(np.c_[X, np.ones(len(X))], Y[:,1])\n",
    "reg_z = LinearRegression().fit(np.c_[X, np.ones(len(X))], Y[:,2])\n",
    "\n",
    "def pixel_to_world(px, py):\n",
    "    vec = np.array([px, py, 1.0])\n",
    "    wx = reg_x.predict([vec])[0]\n",
    "    wy = reg_y.predict([vec])[0]\n",
    "    wz = reg_z.predict([vec])[0]\n",
    "    return wx, wy, wz\n",
    "\n",
    "# Test on one sample\n",
    "print(pixel_to_world(47.0, 121.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calibration_models.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump({\"reg_x\": reg_x, \"reg_y\": reg_y, \"reg_z\": reg_z}, \"calibration_models.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-8.703270604412672e-07, -0.17993528249209165, 0.8715439857456941)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "\n",
    "# --- Features and targets ---\n",
    "X = df[[\"px\", \"py\", \"w\", \"h\"]].values\n",
    "Y = df[[\"world_x\", \"world_y\", \"world_z\"]].values\n",
    "\n",
    "# --- Polynomial regression (degree 2 works well as first test) ---\n",
    "def make_reg():\n",
    "    return make_pipeline(StandardScaler(),\n",
    "                         PolynomialFeatures(degree=2, include_bias=False),\n",
    "                         LinearRegression())\n",
    "\n",
    "reg_x = make_reg()\n",
    "reg_y = make_reg()\n",
    "reg_z = make_reg()\n",
    "\n",
    "# Fit each regressor\n",
    "reg_x.fit(X, Y[:, 0])\n",
    "reg_y.fit(X, Y[:, 1])\n",
    "reg_z.fit(X, Y[:, 2])\n",
    "\n",
    "# --- Prediction function ---\n",
    "def pixel_to_world(px, py, w, h):\n",
    "    features = np.array([[px, py, w, h]])\n",
    "    x = reg_x.predict(features)[0]\n",
    "    y = reg_y.predict(features)[0]\n",
    "    z = reg_z.predict(features)[0]\n",
    "    return x, y, z\n",
    "\n",
    "# --- Example usage ---\n",
    "print(pixel_to_world(47.0, 121.5, 30.0, 29.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poly_models.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump({\"reg_x\": reg_x, \"reg_y\": reg_y, \"reg_z\": reg_z}, \"poly_models.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "#joblib.dump({\"reg_x\": reg_x, \"reg_y\": reg_y, \"reg_z\": reg_z}, \"calibration_models.pkl\")\n",
    "\n",
    "# Load\n",
    "models = joblib.load(\"calibration_models.pkl\")\n",
    "reg_x, reg_y, reg_z = models[\"reg_x\"], models[\"reg_y\"], models[\"reg_z\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the csv files that Start with a name from the given csv_names list and ends with \".csv\" knowing that the files are in the same directory as this script\n",
    "# file names are of the type csv_names[0] + \"_*.csv\"\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "csv_names = [\"Drop\", \"Grasp\", \"ReachPick\", \"ReachDrop\"]\n",
    "\n",
    "files = []\n",
    "for name in csv_names:\n",
    "    files.extend(glob.glob(f\"{name}_*.csv\"))\n",
    "# Load and merge the files found\n",
    "dataframes = [pd.read_csv(file) for file in files]\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new columns \"pred_x\", \"pred_y\", \"pred_z\" to the merged_df dataframe\n",
    "\n",
    "merged_df[\"pred_x\"] = merged_df.apply(lambda row: pixel_to_world(row[\"px\"], row[\"py\"])[0], axis=1)\n",
    "merged_df[\"pred_y\"] = merged_df.apply(lambda row: pixel_to_world(row[\"px\"], row[\"py\"])[1], axis=1)\n",
    "merged_df[\"pred_z\"] = merged_df.apply(lambda row: pixel_to_world(row[\"px\"], row[\"py\"])[2], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the noisy rows where the world pos (world_x, world_y, world_z) is far away from the predicted position (pred_x, pred_y, pred_z)\n",
    "# This is done via statistical analysis of the differences and removing the rows where the difference is greater than 3 standard deviations from the mean\n",
    "\n",
    "def remove_noisy_rows(df):\n",
    "    # Calculate the differences\n",
    "    df[\"diff_x\"] = df[\"world_x\"] - df[\"pred_x\"]\n",
    "    df[\"diff_y\"] = df[\"world_y\"] - df[\"pred_y\"]\n",
    "    df[\"diff_z\"] = df[\"world_z\"] - df[\"pred_z\"]\n",
    "\n",
    "    # Calculate mean and std for each difference\n",
    "    mean_x, std_x = df[\"diff_x\"].mean(), df[\"diff_x\"].std()\n",
    "    mean_y, std_y = df[\"diff_y\"].mean(), df[\"diff_y\"].std()\n",
    "    mean_z, std_z = df[\"diff_z\"].mean(), df[\"diff_z\"].std()\n",
    "\n",
    "    # Filter out rows where the difference is greater than 3 standard deviations from the mean\n",
    "    filtered_df = df[\n",
    "        (np.abs(df[\"diff_x\"] - mean_x) <= 3 * std_x) &\n",
    "        (np.abs(df[\"diff_y\"] - mean_y) <= 3 * std_y) &\n",
    "        (np.abs(df[\"diff_z\"] - mean_z) <= 3 * std_z)\n",
    "    ]\n",
    "\n",
    "    return filtered_df\n",
    "clean_df = remove_noisy_rows(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the merged_df dataframe with only the columns \"px\", \"py\", \"w\", \"h\", \"world_x\", \"world_y\", \"world_z\", \"pred_x\", \"pred_y\", \"pred_z\"\n",
    "filtered_df = clean_df[[\"px\", \"py\", \"w\", \"h\", \"world_x\", \"world_y\", \"world_z\", \"pred_x\", \"pred_y\", \"pred_z\"]].copy()\n",
    "\n",
    "\n",
    "#filtered_df[\"world_x\"] -= 0.005\n",
    "#filtered_df[\"world_y\"] += 0.0\n",
    "#[-10,14,0]\n",
    "# Add a small offset to the world_z values (2mm)\n",
    "filtered_df[\"world_z\"] += 0.008\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>conf</th>\n",
       "      <th>cls</th>\n",
       "      <th>world_x</th>\n",
       "      <th>world_y</th>\n",
       "      <th>world_z</th>\n",
       "      <th>pred_x</th>\n",
       "      <th>pred_y</th>\n",
       "      <th>pred_z</th>\n",
       "      <th>diff_x</th>\n",
       "      <th>diff_y</th>\n",
       "      <th>diff_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.914762</td>\n",
       "      <td>red cube</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-0.180318</td>\n",
       "      <td>0.871774</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>0.868439</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>0.003335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>136.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.880062</td>\n",
       "      <td>green cube</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-0.180118</td>\n",
       "      <td>0.824637</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>-0.177679</td>\n",
       "      <td>0.830204</td>\n",
       "      <td>-0.001987</td>\n",
       "      <td>-0.002439</td>\n",
       "      <td>-0.005567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.858274</td>\n",
       "      <td>blue cube</td>\n",
       "      <td>0.012234</td>\n",
       "      <td>0.233919</td>\n",
       "      <td>0.943752</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.219203</td>\n",
       "      <td>0.934911</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.014716</td>\n",
       "      <td>0.008842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.914762</td>\n",
       "      <td>red cube</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-0.180318</td>\n",
       "      <td>0.871774</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>0.868439</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>0.003335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>244.0</td>\n",
       "      <td>96.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.890489</td>\n",
       "      <td>blue cube</td>\n",
       "      <td>0.012234</td>\n",
       "      <td>0.233919</td>\n",
       "      <td>0.943752</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.218651</td>\n",
       "      <td>0.931089</td>\n",
       "      <td>0.009354</td>\n",
       "      <td>0.015268</td>\n",
       "      <td>0.012663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      px     py     w     h      conf         cls   world_x   world_y  \\\n",
       "0   47.0  121.5  30.0  29.0  0.914762    red cube  0.000131 -0.180318   \n",
       "1   51.0  136.5  30.0  31.0  0.880062  green cube  0.000073 -0.180118   \n",
       "2  244.0   95.0  24.0  30.0  0.858274   blue cube  0.012234  0.233919   \n",
       "3   47.0  121.5  30.0  29.0  0.914762    red cube  0.000131 -0.180318   \n",
       "4  244.0   96.5  24.0  31.0  0.890489   blue cube  0.012234  0.233919   \n",
       "\n",
       "    world_z    pred_x    pred_y    pred_z    diff_x    diff_y    diff_z  \n",
       "0  0.871774 -0.000543 -0.180069  0.868439  0.000674 -0.000249  0.003335  \n",
       "1  0.824637  0.002060 -0.177679  0.830204 -0.001987 -0.002439 -0.005567  \n",
       "2  0.943752  0.002635  0.219203  0.934911  0.009599  0.014716  0.008842  \n",
       "3  0.871774 -0.000543 -0.180069  0.868439  0.000674 -0.000249  0.003335  \n",
       "4  0.943752  0.002880  0.218651  0.931089  0.009354  0.015268  0.012663  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>world_x</th>\n",
       "      <th>world_y</th>\n",
       "      <th>world_z</th>\n",
       "      <th>pred_x</th>\n",
       "      <th>pred_y</th>\n",
       "      <th>pred_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-0.158318</td>\n",
       "      <td>0.879774</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>0.868439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.0</td>\n",
       "      <td>136.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-0.158118</td>\n",
       "      <td>0.832637</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>-0.177679</td>\n",
       "      <td>0.830204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>244.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.012234</td>\n",
       "      <td>0.255919</td>\n",
       "      <td>0.951752</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.219203</td>\n",
       "      <td>0.934911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-0.158318</td>\n",
       "      <td>0.879774</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>0.868439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>244.0</td>\n",
       "      <td>96.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.012234</td>\n",
       "      <td>0.255919</td>\n",
       "      <td>0.951752</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.218651</td>\n",
       "      <td>0.931089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      px     py     w     h   world_x   world_y   world_z    pred_x    pred_y  \\\n",
       "0   47.0  121.5  30.0  29.0  0.000131 -0.158318  0.879774 -0.000543 -0.180069   \n",
       "1   51.0  136.5  30.0  31.0  0.000073 -0.158118  0.832637  0.002060 -0.177679   \n",
       "2  244.0   95.0  24.0  30.0  0.012234  0.255919  0.951752  0.002635  0.219203   \n",
       "3   47.0  121.5  30.0  29.0  0.000131 -0.158318  0.879774 -0.000543 -0.180069   \n",
       "4  244.0   96.5  24.0  31.0  0.012234  0.255919  0.951752  0.002880  0.218651   \n",
       "\n",
       "     pred_z  \n",
       "0  0.868439  \n",
       "1  0.830204  \n",
       "2  0.934911  \n",
       "3  0.868439  \n",
       "4  0.931089  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.00032867255568820586, -0.16053407417998278, 0.8741101523804948)\n"
     ]
    }
   ],
   "source": [
    "# Retrain linear regression with the filtered data\n",
    "X_filtered = filtered_df[[\"px\", \"py\"]].values\n",
    "Y_filtered = filtered_df[[\"world_x\", \"world_y\", \"world_z\"]].values\n",
    "reg_x_filtered = LinearRegression().fit(np.c_[X_filtered, np.ones(len(X_filtered))], Y_filtered[:,0])\n",
    "reg_y_filtered = LinearRegression().fit(np.c_[X_filtered, np.ones(len(X_filtered))], Y_filtered[:,1])\n",
    "reg_z_filtered = LinearRegression().fit(np.c_[X_filtered, np.ones(len(X_filtered))], Y_filtered[:,2])\n",
    "def pixel_to_world_filtered(px, py):\n",
    "    vec = np.array([px, py, 1.0])\n",
    "    wx = reg_x_filtered.predict([vec])[0]\n",
    "    wy = reg_y_filtered.predict([vec])[0]\n",
    "    wz = reg_z_filtered.predict([vec])[0]\n",
    "    return wx, wy, wz\n",
    "\n",
    "# Test on one sample\n",
    "print(pixel_to_world_filtered(47.0, 121.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error X: 2.194672507663093e-18, Std Error X: 0.004136811470553184\n",
      "Mean Error Y: 3.395657342956362e-17, Std Error Y: 0.010720729096946739\n",
      "Mean Error Z: 6.456671076033535e-17, Std Error Z: 0.005916039767177171\n"
     ]
    }
   ],
   "source": [
    "# Replace pred columns with the filtered predictions\n",
    "\n",
    "filtered_df[\"pred_x\"] = filtered_df.apply(lambda row: pixel_to_world_filtered(row[\"px\"], row[\"py\"])[0], axis=1)\n",
    "filtered_df[\"pred_y\"] = filtered_df.apply(lambda row: pixel_to_world_filtered(row[\"px\"], row[\"py\"])[1], axis=1)\n",
    "filtered_df[\"pred_z\"] = filtered_df.apply(lambda row: pixel_to_world_filtered(row[\"px\"], row[\"py\"])[2], axis=1)\n",
    "\n",
    "# Compute the differences between the world and predicted positions\n",
    "filtered_df[\"diff_x\"] = filtered_df[\"world_x\"] - filtered_df[\"pred_x\"]\n",
    "filtered_df[\"diff_y\"] = filtered_df[\"world_y\"] - filtered_df[\"pred_y\"]\n",
    "filtered_df[\"diff_z\"] = filtered_df[\"world_z\"] - filtered_df[\"pred_z\"]\n",
    "\n",
    "# Compute the error metrics\n",
    "mean_error_x = filtered_df[\"diff_x\"].mean()\n",
    "mean_error_y = filtered_df[\"diff_y\"].mean()\n",
    "mean_error_z = filtered_df[\"diff_z\"].mean()\n",
    "std_error_x = filtered_df[\"diff_x\"].std()\n",
    "std_error_y = filtered_df[\"diff_y\"].std()\n",
    "std_error_z = filtered_df[\"diff_z\"].std()\n",
    "print(f\"Mean Error X: {mean_error_x}, Std Error X: {std_error_x}\")\n",
    "print(f\"Mean Error Y: {mean_error_y}, Std Error Y: {std_error_y}\")\n",
    "print(f\"Mean Error Z: {mean_error_z}, Std Error Z: {std_error_z}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filtered_calibration_models.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the filtered models\n",
    "joblib.dump({\"reg_x\": reg_x_filtered, \"reg_y\": reg_y_filtered, \"reg_z\": reg_z_filtered}, \"filtered_calibration_models.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base regression models\n",
    "import joblib\n",
    "models = joblib.load(\"calibration_models.pkl\")\n",
    "reg_x, reg_y, reg_z = models[\"reg_x\"], models[\"reg_y\"], models[\"reg_z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yolo_data_4.csv']\n"
     ]
    }
   ],
   "source": [
    "#### LEARN FROM DUAL CAMS ####\n",
    "\n",
    "# Find all the csv files that Start with a name from the given csv_names list and ends with \".csv\" knowing that the files are in the same directory as this script\n",
    "# file names are of the type csv_names[0] + \"_*.csv\"\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_names = [\"Drop\", \"Grasp\", \"ReachPick\", \"ReachDrop\", \"yolo\"]\n",
    "\n",
    "files = []\n",
    "for name in csv_names:\n",
    "    files.extend(glob.glob(f\"{name}_*.csv\"))\n",
    "print(files)\n",
    "# Load and merge the files found\n",
    "dataframes = [pd.read_csv(file) for file in files]\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51987"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new columns \"pred_x\", \"pred_y\", \"pred_z\" to the merged_df dataframe\n",
    "def pixel_to_world(px, py):\n",
    "    vec = np.array([px, py, 1.0])\n",
    "    wx = reg_x.predict([vec])[0]\n",
    "    wy = reg_y.predict([vec])[0]\n",
    "    wz = reg_z.predict([vec])[0]\n",
    "    return wx, wy, wz\n",
    "\n",
    "merged_df[\"pred_x\"] = merged_df.apply(lambda row: pixel_to_world(row[\"px_cam1\"], row[\"py_cam1\"])[0], axis=1)\n",
    "merged_df[\"pred_y\"] = merged_df.apply(lambda row: pixel_to_world(row[\"px_cam1\"], row[\"py_cam1\"])[1], axis=1)\n",
    "merged_df[\"pred_z\"] = merged_df.apply(lambda row: pixel_to_world(row[\"px_cam1\"], row[\"py_cam1\"])[2], axis=1)\n",
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the noisy rows where the world pos (world_x, world_y, world_z) is far away from the predicted position (pred_x, pred_y, pred_z)\n",
    "# This is done via statistical analysis of the differences and removing the rows where the difference is greater than 3 standard deviations from the mean\n",
    "\n",
    "def remove_noisy_rows(df):\n",
    "    # Calculate the differences\n",
    "    df[\"diff_x\"] = df[\"world_x\"] - df[\"pred_x\"]\n",
    "    df[\"diff_y\"] = df[\"world_y\"] - df[\"pred_y\"]\n",
    "    df[\"diff_z\"] = df[\"world_z\"] - df[\"pred_z\"]\n",
    "\n",
    "    # Calculate mean and std for each difference\n",
    "    mean_x, std_x = df[\"diff_x\"].mean(), df[\"diff_x\"].std()\n",
    "    mean_y, std_y = df[\"diff_y\"].mean(), df[\"diff_y\"].std()\n",
    "    mean_z, std_z = df[\"diff_z\"].mean(), df[\"diff_z\"].std()\n",
    "\n",
    "    # Filter out rows where the difference is greater than 3 standard deviations from the mean\n",
    "    filtered_df = df[\n",
    "        (np.abs(df[\"diff_x\"] - mean_x) <= 3 * std_x) &\n",
    "        (np.abs(df[\"diff_y\"] - mean_y) <= 3 * std_y) &\n",
    "        (np.abs(df[\"diff_z\"] - mean_z) <= 3 * std_z)\n",
    "    ]\n",
    "\n",
    "    return filtered_df\n",
    "clean_df = remove_noisy_rows(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the merged_df dataframe with only the columns \"px_cam1\", \"py_cam1\", \"w_cam1\", \"h_cam1\", \"conf_cam1\", \"px_cam2\", \"py_cam2\", \"w_cam2\", \"h_cam2\", \"conf_cam2\", \"world_x\", \"world_y\", \"world_z\", \"ee_x\", \"ee_y\", \"ee_z\", \"pred_x\", \"pred_y\", \"pred_z\"\n",
    "\n",
    "filtered_df = clean_df[[\"px_cam1\", \"py_cam1\", \"w_cam1\", \"h_cam1\", \"conf_cam1\", \"px_cam2\", \"py_cam2\", \"w_cam2\", \"h_cam2\", \"conf_cam2\", \"world_x\", \"world_y\", \"world_z\", \"ee_x\", \"ee_y\", \"ee_z\", \"pred_x\", \"pred_y\", \"pred_z\"]].copy()\n",
    "\n",
    "filtered_df[\"world_z\"] += 0.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px_cam1</th>\n",
       "      <th>py_cam1</th>\n",
       "      <th>w_cam1</th>\n",
       "      <th>h_cam1</th>\n",
       "      <th>conf_cam1</th>\n",
       "      <th>px_cam2</th>\n",
       "      <th>py_cam2</th>\n",
       "      <th>w_cam2</th>\n",
       "      <th>h_cam2</th>\n",
       "      <th>conf_cam2</th>\n",
       "      <th>world_x</th>\n",
       "      <th>world_y</th>\n",
       "      <th>world_z</th>\n",
       "      <th>ee_x</th>\n",
       "      <th>ee_y</th>\n",
       "      <th>ee_z</th>\n",
       "      <th>pred_x</th>\n",
       "      <th>pred_y</th>\n",
       "      <th>pred_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>0.940421</td>\n",
       "      <td>97</td>\n",
       "      <td>108</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>0.845666</td>\n",
       "      <td>1.698589e-19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.827784</td>\n",
       "      <td>-0.078850</td>\n",
       "      <td>-0.02540</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>-0.009795</td>\n",
       "      <td>0.828482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>135</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>0.923580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.330247e-19</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.832784</td>\n",
       "      <td>-0.078850</td>\n",
       "      <td>-0.02540</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>-0.179105</td>\n",
       "      <td>0.834031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222</td>\n",
       "      <td>136</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>0.908191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.061430e-19</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.830284</td>\n",
       "      <td>-0.078850</td>\n",
       "      <td>-0.02540</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>0.160618</td>\n",
       "      <td>0.830577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>0.940767</td>\n",
       "      <td>98</td>\n",
       "      <td>111</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0.862378</td>\n",
       "      <td>1.750184e-19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.827784</td>\n",
       "      <td>-0.074212</td>\n",
       "      <td>-0.02343</td>\n",
       "      <td>0.936162</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>-0.009795</td>\n",
       "      <td>0.828482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>135</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>0.923963</td>\n",
       "      <td>237</td>\n",
       "      <td>111</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>0.571598</td>\n",
       "      <td>-1.230897e-19</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.832784</td>\n",
       "      <td>-0.074212</td>\n",
       "      <td>-0.02343</td>\n",
       "      <td>0.936162</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>-0.179105</td>\n",
       "      <td>0.834031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   px_cam1  py_cam1  w_cam1  h_cam1  conf_cam1  px_cam2  py_cam2  w_cam2  \\\n",
       "0      136      137      20      25   0.940421       97      108      30   \n",
       "1       50      135      30      32   0.923580        0        0       0   \n",
       "2      222      136      30      29   0.908191        0        0       0   \n",
       "3      136      137      20      25   0.940767       98      111      29   \n",
       "4       50      135      30      32   0.923963      237      111      36   \n",
       "\n",
       "   h_cam2  conf_cam2       world_x  world_y   world_z      ee_x     ee_y  \\\n",
       "0      29   0.845666  1.698589e-19     0.02  0.827784 -0.078850 -0.02540   \n",
       "1       0   0.000000 -1.330247e-19    -0.18  0.832784 -0.078850 -0.02540   \n",
       "2       0   0.000000 -1.061430e-19     0.22  0.830284 -0.078850 -0.02540   \n",
       "3      29   0.862378  1.750184e-19     0.02  0.827784 -0.074212 -0.02343   \n",
       "4      37   0.571598 -1.230897e-19    -0.18  0.832784 -0.074212 -0.02343   \n",
       "\n",
       "       ee_z    pred_x    pred_y    pred_z  \n",
       "0  0.936416  0.005380 -0.009795  0.828482  \n",
       "1  0.936416  0.001777 -0.179105  0.834031  \n",
       "2  0.936416  0.008494  0.160618  0.830577  \n",
       "3  0.936162  0.005380 -0.009795  0.828482  \n",
       "4  0.936162  0.001777 -0.179105  0.834031  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50765"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m reg_z_dual \u001b[38;5;241m=\u001b[39m make_reg()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Fit each regressor\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mreg_x_dual\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_dual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_dual\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m reg_y_dual\u001b[38;5;241m.\u001b[39mfit(X_dual, Y_dual[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     18\u001b[0m reg_z_dual\u001b[38;5;241m.\u001b[39mfit(X_dual, Y_dual[:, \u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    426\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 427\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py:751\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m outs])\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingular_ \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/enigma/lib/python3.8/site-packages/scipy/linalg/_basic.py:1213\u001b[0m, in \u001b[0;36mlstsq\u001b[0;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m real_data:\n\u001b[1;32m   1212\u001b[0m     lwork, iwork \u001b[38;5;241m=\u001b[39m _compute_lwork(lapack_lwork, m, n, nrhs, cond)\n\u001b[0;32m-> 1213\u001b[0m     x, s, rank, info \u001b[38;5;241m=\u001b[39m \u001b[43mlapack_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43miwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# complex data\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m     lwork, rwork, iwork \u001b[38;5;241m=\u001b[39m _compute_lwork(lapack_lwork, m, n,\n\u001b[1;32m   1217\u001b[0m                                          nrhs, cond)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train a new polynomial regression model with the dual cam data + ee pos\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "# --- Features and targets ---\n",
    "X_dual = filtered_df[[\"px_cam1\", \"py_cam1\", \"w_cam1\", \"h_cam1\", \"conf_cam1\", \"px_cam2\", \"py_cam2\", \"w_cam2\", \"h_cam2\", \"conf_cam2\", \"ee_x\", \"ee_y\", \"ee_z\"]].values\n",
    "Y_dual = filtered_df[[\"world_x\", \"world_y\", \"world_z\"]].values\n",
    "# --- Polynomial regression (degree 2 works well as first test) ---\n",
    "def make_reg():\n",
    "    return make_pipeline(StandardScaler(),\n",
    "                         PolynomialFeatures(degree=5, include_bias=False),\n",
    "                         LinearRegression())\n",
    "reg_x_dual = make_reg()\n",
    "reg_y_dual = make_reg()\n",
    "reg_z_dual = make_reg()\n",
    "\n",
    "# Fit each regressor\n",
    "reg_x_dual.fit(X_dual, Y_dual[:, 0])\n",
    "reg_y_dual.fit(X_dual, Y_dual[:, 1])\n",
    "reg_z_dual.fit(X_dual, Y_dual[:, 2])\n",
    "def pixel_to_world_dual(px1, py1, w1, h1, conf1, px2, py2, w2, h2, conf2, ee_x, ee_y, ee_z):\n",
    "    features = np.array([[px1, py1, w1, h1, conf1, px2, py2, w2, h2, conf2, ee_x, ee_y, ee_z]])\n",
    "    x = reg_x_dual.predict(features)[0]\n",
    "    y = reg_y_dual.predict(features)[0]\n",
    "    z = reg_z_dual.predict(features)[0]\n",
    "    return x, y, z\n",
    "\n",
    "# --- Example usage ---\n",
    "# Get a prediction for the first row of the filtered_df dataframe\n",
    "px1, py1, w1, h1, conf1 = filtered_df.iloc[0][[\"px_cam1\", \"py_cam1\", \"w_cam1\", \"h_cam1\", \"conf_cam1\"]]\n",
    "px2, py2, w2, h2, conf2 = filtered_df.iloc[0][[\"px_cam2\", \"py_cam2\", \"w_cam2\", \"h_cam2\", \"conf_cam2\"]]\n",
    "ee_x, ee_y, ee_z = filtered_df.iloc[0][[\"ee_x\", \"ee_y\", \"ee_z\"]]\n",
    "print(pixel_to_world_dual(px1, py1, w1, h1, conf1, px2, py2, w2, h2, conf2, ee_x, ee_y, ee_z))\n",
    "print(filtered_df.iloc[0][[\"world_x\", \"world_y\", \"world_z\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-2.9732311645179773e-07, 0.01994981820511498, 0.8278254660471982)\n",
      "[1.69858918e-19 2.00000000e-02 8.27784489e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "X_dual = filtered_df[[\"px_cam1\", \"py_cam1\", \"w_cam1\", \"h_cam1\", \"conf_cam1\", \"px_cam2\", \"py_cam2\", \"w_cam2\", \"h_cam2\", \"conf_cam2\", \"ee_x\", \"ee_y\", \"ee_z\"]].values\n",
    "Y_dual = filtered_df[[\"world_x\", \"world_y\", \"world_z\"]].values\n",
    "\n",
    "reg_x_dual = GradientBoostingRegressor(n_estimators=200, max_depth=3, learning_rate=0.1)\n",
    "reg_y_dual = GradientBoostingRegressor(n_estimators=200, max_depth=3, learning_rate=0.1)\n",
    "reg_z_dual = GradientBoostingRegressor(n_estimators=200, max_depth=3, learning_rate=0.1)\n",
    "\n",
    "reg_x_dual.fit(X_dual, Y_dual[:, 0])\n",
    "reg_y_dual.fit(X_dual, Y_dual[:, 1])\n",
    "reg_z_dual.fit(X_dual, Y_dual[:, 2])\n",
    "def pixel_to_world_dual(px1, py1, w1, h1, conf1, px2, py2, w2, h2, conf2, ee_x, ee_y, ee_z):\n",
    "    features = np.array([[px1, py1, w1, h1, conf1, px2, py2, w2, h2, conf2, ee_x, ee_y, ee_z]])\n",
    "    x = reg_x_dual.predict(features)[0]\n",
    "    y = reg_y_dual.predict(features)[0]\n",
    "    z = reg_z_dual.predict(features)[0]\n",
    "    return x, y, z\n",
    "# --- Example usage ---\n",
    "# Get a prediction for the first row of the filtered_df dataframe\n",
    "px1, py1, w1, h1, conf1 = filtered_df.iloc[0][[\"px_cam1\", \"py_cam1\", \"w_cam1\", \"h_cam1\", \"conf_cam1\"]]\n",
    "px2, py2, w2, h2, conf2 = filtered_df.iloc[0][[\"px_cam2\", \"py_cam2\", \"w_cam2\", \"h_cam2\", \"conf_cam2\"]]\n",
    "ee_x, ee_y, ee_z = filtered_df.iloc[0][[\"ee_x\", \"ee_y\", \"ee_z\"]]\n",
    "print(pixel_to_world_dual(px1, py1, w1, h1, conf1, px2, py2, w2, h2, conf2, ee_x, ee_y, ee_z))\n",
    "print(filtered_df.iloc[0][[\"world_x\", \"world_y\", \"world_z\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace pred columns with the dual cam predictions\n",
    "filtered_df[\"pred_x\"] = filtered_df.apply(lambda row: pixel_to_world_dual(row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[0], axis=1)\n",
    "filtered_df[\"pred_y\"] = filtered_df.apply(lambda row: pixel_to_world_dual(row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[1], axis=1)\n",
    "filtered_df[\"pred_z\"] = filtered_df.apply(lambda row: pixel_to_world_dual(row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[2], axis=1)\n",
    "\n",
    "# Compute the differences between the world and predicted positions\n",
    "filtered_df[\"diff_x\"] = filtered_df[\"world_x\"] - filtered_df[\"pred_x\"]\n",
    "filtered_df[\"diff_y\"] = filtered_df[\"world_y\"] - filtered_df[\"pred_y\"]\n",
    "filtered_df[\"diff_z\"] = filtered_df[\"world_z\"] - filtered_df[\"pred_z\"]\n",
    "\n",
    "# Compute the error metrics\n",
    "mean_error_x = filtered_df[\"diff_x\"].mean()\n",
    "mean_error_y = filtered_df[\"diff_y\"].mean()\n",
    "mean_error_z = filtered_df[\"diff_z\"].mean()\n",
    "std_error_x = filtered_df[\"diff_x\"].std()\n",
    "std_error_y = filtered_df[\"diff_y\"].std()\n",
    "std_error_z = filtered_df[\"diff_z\"].std()\n",
    "print(f\"Mean Error X: {mean_error_x}, Std Error X: {std_error_x}\")\n",
    "print(f\"Mean Error Y: {mean_error_y}, Std Error Y: {std_error_y}\")\n",
    "print(f\"Mean Error Z: {mean_error_z}, Std Error Z: {std_error_z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error X: 7.741512536792649e-20, Std Error X: 0.0008793294829363763\n",
      "Mean Error Y: -1.5314735350672477e-17, Std Error Y: 0.0010732572754690844\n",
      "Mean Error Z: -5.846042994875362e-17, Std Error Z: 0.0008155256801207981\n"
     ]
    }
   ],
   "source": [
    "# Replace pred columns with the dual cam predictions\n",
    "filtered_df[\"pred_x\"] = filtered_df.apply(lambda row: pixel_to_world_dual(row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[0], axis=1)\n",
    "filtered_df[\"pred_y\"] = filtered_df.apply(lambda row: pixel_to_world_dual(row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[1], axis=1)\n",
    "filtered_df[\"pred_z\"] = filtered_df.apply(lambda row: pixel_to_world_dual(row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[2], axis=1)\n",
    "\n",
    "# Compute the differences between the world and predicted positions\n",
    "filtered_df[\"diff_x\"] = filtered_df[\"world_x\"] - filtered_df[\"pred_x\"]\n",
    "filtered_df[\"diff_y\"] = filtered_df[\"world_y\"] - filtered_df[\"pred_y\"]\n",
    "filtered_df[\"diff_z\"] = filtered_df[\"world_z\"] - filtered_df[\"pred_z\"]\n",
    "\n",
    "# Compute the error metrics\n",
    "mean_error_x = filtered_df[\"diff_x\"].mean()\n",
    "mean_error_y = filtered_df[\"diff_y\"].mean()\n",
    "mean_error_z = filtered_df[\"diff_z\"].mean()\n",
    "std_error_x = filtered_df[\"diff_x\"].std()\n",
    "std_error_y = filtered_df[\"diff_y\"].std()\n",
    "std_error_z = filtered_df[\"diff_z\"].std()\n",
    "print(f\"Mean Error X: {mean_error_x}, Std Error X: {std_error_x}\")\n",
    "print(f\"Mean Error Y: {mean_error_y}, Std Error Y: {std_error_y}\")\n",
    "print(f\"Mean Error Z: {mean_error_z}, Std Error Z: {std_error_z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dual_cam_calibration_models.pkl']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the dual cam models\n",
    "joblib.dump({\"reg_x\": reg_x_dual, \"reg_y\": reg_y_dual, \"reg_z\": reg_z_dual}, \"dual_cam_calibration_models.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4790676546961885e-05, 0.019987686773308935, 0.8277852845283147)\n",
      "[1.69858918e-19 2.00000000e-02 8.27784489e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "X_dual = filtered_df[[\"px_cam1\", \"py_cam1\", \"w_cam1\", \"h_cam1\", \"conf_cam1\", \"px_cam2\", \"py_cam2\", \"w_cam2\", \"h_cam2\", \"conf_cam2\", \"ee_x\", \"ee_y\", \"ee_z\"]].values\n",
    "Y_dual = filtered_df[[\"world_x\", \"world_y\", \"world_z\"]].values\n",
    "\n",
    "reg_x_dual = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "reg_y_dual = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "reg_z_dual = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "\n",
    "reg_x_dual.fit(X_dual, Y_dual[:, 0])\n",
    "reg_y_dual.fit(X_dual, Y_dual[:, 1])\n",
    "reg_z_dual.fit(X_dual, Y_dual[:, 2])\n",
    "def pixel_to_world_dual(px1, py1, w1, h1, conf1, px2, py2, w2, h2, conf2, ee_x, ee_y, ee_z):\n",
    "    features = np.array([[px1, py1, w1, h1, conf1, px2, py2, w2, h2, conf2, ee_x, ee_y, ee_z]])\n",
    "    x = reg_x_dual.predict(features)[0]\n",
    "    y = reg_y_dual.predict(features)[0]\n",
    "    z = reg_z_dual.predict(features)[0]\n",
    "    return x, y, z\n",
    "# --- Example usage ---\n",
    "# Get a prediction for the first row of the filtered_df dataframe\n",
    "px1, py1, w1, h1, conf1 = filtered_df.iloc[0][[\"px_cam1\", \"py_cam1\", \"w_cam1\", \"h_cam1\", \"conf_cam1\"]]\n",
    "px2, py2, w2, h2, conf2 = filtered_df.iloc[0][[\"px_cam2\", \"py_cam2\", \"w_cam2\", \"h_cam2\", \"conf_cam2\"]]\n",
    "ee_x, ee_y, ee_z = filtered_df.iloc[0][[\"ee_x\", \"ee_y\", \"ee_z\"]]\n",
    "print(pixel_to_world_dual(px1, py1, w1, h1, conf1, px2, py2, w2, h2, conf2, ee_x, ee_y, ee_z))\n",
    "print(filtered_df.iloc[0][[\"world_x\", \"world_y\", \"world_z\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error X: -1.5636196816180205e-06, Std Error X: 0.0005645848941660973\n",
      "Mean Error Y: 3.3442651240772504e-07, Std Error Y: 0.0007365071757306728\n",
      "Mean Error Z: -7.759937644472823e-07, Std Error Z: 0.0003579350943676746\n"
     ]
    }
   ],
   "source": [
    "# Replace pred columns with the dual cam predictions\n",
    "filtered_df[\"pred_x\"] = filtered_df.apply(lambda row: pixel_to_world_dual(row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[0], axis=1)\n",
    "filtered_df[\"pred_y\"] = filtered_df.apply(lambda row: pixel_to_world_dual(row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[1], axis=1)\n",
    "filtered_df[\"pred_z\"] = filtered_df.apply(lambda row: pixel_to_world_dual(row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[2], axis=1)\n",
    "\n",
    "# Compute the differences between the world and predicted positions\n",
    "filtered_df[\"diff_x\"] = filtered_df[\"world_x\"] - filtered_df[\"pred_x\"]\n",
    "filtered_df[\"diff_y\"] = filtered_df[\"world_y\"] - filtered_df[\"pred_y\"]\n",
    "filtered_df[\"diff_z\"] = filtered_df[\"world_z\"] - filtered_df[\"pred_z\"]\n",
    "\n",
    "# Compute the error metrics\n",
    "mean_error_x = filtered_df[\"diff_x\"].mean()\n",
    "mean_error_y = filtered_df[\"diff_y\"].mean()\n",
    "mean_error_z = filtered_df[\"diff_z\"].mean()\n",
    "std_error_x = filtered_df[\"diff_x\"].std()\n",
    "std_error_y = filtered_df[\"diff_y\"].std()\n",
    "std_error_z = filtered_df[\"diff_z\"].std()\n",
    "print(f\"Mean Error X: {mean_error_x}, Std Error X: {std_error_x}\")\n",
    "print(f\"Mean Error Y: {mean_error_y}, Std Error Y: {std_error_y}\")\n",
    "print(f\"Mean Error Z: {mean_error_z}, Std Error Z: {std_error_z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Error X: 5.207707027316054e-16, Std Error X: 0.0013200825027191241\n",
      "Mean Error Y: 1.1677341442863136e-15, Std Error Y: 0.0018794034669458873\n",
      "Mean Error Z: 2.02529678151545e-15, Std Error Z: 0.0020466680696900378\n"
     ]
    }
   ],
   "source": [
    "# Replace pred columns with the dual cam predictions\n",
    "filtered_df[\"pred_x\"] = filtered_df.apply(lambda row: pixel_to_world_dual(row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[0], axis=1)\n",
    "filtered_df[\"pred_y\"] = filtered_df.apply(lambda row: pixel_to_world_dual(row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[1], axis=1)\n",
    "filtered_df[\"pred_z\"] = filtered_df.apply(lambda row: pixel_to_world_dual(row[\"px_cam1\"], row[\"py_cam1\"], row[\"w_cam1\"], row[\"h_cam1\"], row[\"conf_cam1\"], row[\"px_cam2\"], row[\"py_cam2\"], row[\"w_cam2\"], row[\"h_cam2\"], row[\"conf_cam2\"], row[\"ee_x\"], row[\"ee_y\"], row[\"ee_z\"])[2], axis=1)\n",
    "\n",
    "# Compute the differences between the world and predicted positions\n",
    "filtered_df[\"diff_x\"] = filtered_df[\"world_x\"] - filtered_df[\"pred_x\"]\n",
    "filtered_df[\"diff_y\"] = filtered_df[\"world_y\"] - filtered_df[\"pred_y\"]\n",
    "filtered_df[\"diff_z\"] = filtered_df[\"world_z\"] - filtered_df[\"pred_z\"]\n",
    "\n",
    "# Compute the error metrics\n",
    "mean_error_x = filtered_df[\"diff_x\"].mean()\n",
    "mean_error_y = filtered_df[\"diff_y\"].mean()\n",
    "mean_error_z = filtered_df[\"diff_z\"].mean()\n",
    "std_error_x = filtered_df[\"diff_x\"].std()\n",
    "std_error_y = filtered_df[\"diff_y\"].std()\n",
    "std_error_z = filtered_df[\"diff_z\"].std()\n",
    "print(f\"Mean Error X: {mean_error_x}, Std Error X: {std_error_x}\")\n",
    "print(f\"Mean Error Y: {mean_error_y}, Std Error Y: {std_error_y}\")\n",
    "print(f\"Mean Error Z: {mean_error_z}, Std Error Z: {std_error_z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dual_cam_calibration_models.pkl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the dual cam models\n",
    "joblib.dump({\"reg_x\": reg_x_dual, \"reg_y\": reg_y_dual, \"reg_z\": reg_z_dual}, \"dual_cam_calibration_models.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dual cam models\n",
    "models_dual = joblib.load(\"dual_cam_calibration_models.pkl\")\n",
    "reg_x_dual, reg_y_dual, reg_z_dual = models_dual[\"reg_x\"], models_dual[\"reg_y\"], models_dual[\"reg_z\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enigma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
